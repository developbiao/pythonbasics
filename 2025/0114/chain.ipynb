{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27dfaffc-bd15-4c87-be57-87e0e87a6eb4",
   "metadata": {},
   "source": [
    "## Chain\n",
    "\n",
    "### Goals\n",
    "Now, let's build up to a simple chain that combines 4 concepts:\n",
    "- Using chat messages as our graph state\n",
    "- Using chat models in graph nodes\n",
    "- Binding tools to our chat model\n",
    "- Executing tool calls in graph nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a076b81-2f99-4386-8e25-fa87b6286de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langchain_openai langchain_core langgraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01a1b4e-3764-48d1-a2bd-8e7abe351abe",
   "metadata": {},
   "source": [
    "### Messages\n",
    "- HumanMessage, AIMessage, SsytemMessage, ToolMessage\n",
    "  \n",
    "- Each message can be supplied with a few tings:\n",
    "  - content\n",
    "  - name\n",
    "  - response_metadata (optionally)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74bbdf50-f4af-43fd-9606-25992d3b4a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: Model\n",
      "\n",
      "So you said you were researcing ocean mammals?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: Lance\n",
      "\n",
      "Yes, that's right.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: Model\n",
      "\n",
      "Great, what would you like to learn about.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: Lance\n",
      "\n",
      "I want to learn about the best place to see Orcas in the US.\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "messages = [AIMessage(content=f\"So you said you were researcing ocean mammals?\", name=\"Model\")]\n",
    "messages.append(HumanMessage(content=f\"Yes, that's right.\", name=\"Lance\"))\n",
    "messages.append(AIMessage(content=\"Great, what would you like to learn about.\", name=\"Model\"))\n",
    "messages.append(HumanMessage(content=\"I want to learn about the best place to see Orcas in the US.\", name=\"Lance\"))\n",
    "\n",
    "for m in messages:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef16f25-69c7-4037-8d5d-627fe39959fb",
   "metadata": {},
   "source": [
    "### Chat Models\n",
    "Leet's check chat your `GOOGLE_API_KEY`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3afe8a25-631e-4dd2-b974-b8113099f456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:7897 Hi\n"
     ]
    }
   ],
   "source": [
    "import os, getpass\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}:\")\n",
    "# set proxy\n",
    "_set_env(\"PROXY_VALUE\")\n",
    "proxy = os.getenv(\"PROXY_VALUE\")\n",
    "for proxy_var in ['HTTP_PROXY', 'HTTPS_PROXY', 'http_proxy', 'https_proxy']:\n",
    "    os.environ[proxy_var] = proxy\n",
    "# GOOGLE API KEY\n",
    "_set_env(\"GOOGLE_API_KEY\")\n",
    "\n",
    "print(os.environ[\"PROXY_VALUE\"], \"Hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b4e217c-27d1-49e1-8f91-a0bca9678502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87f1fb58-ed74-46fd-97d2-3a72356a7ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='There\\'s no single \"best\" place to see orcas in the US, as it depends on the time of year and what kind of experience you\\'re looking for.  Orcas (killer whales) have different populations with varying ranges.  However, some of the most popular and reliable locations include:\\n\\n* **Alaska:** This is arguably the best overall location for orca viewing in the US.  Several different populations of orcas frequent Alaskan waters, offering excellent opportunities for sightings.  Specific locations include:\\n    * **Southeast Alaska:**  Offers opportunities to see both resident and transient orcas.  Cruises are common from Juneau, Ketchikan, and other towns.\\n    * **Prince William Sound:** Known for its resident orca pods.\\n    * **Kenai Fjords National Park:**  Offers a chance to see orcas alongside other wildlife.\\n\\n* **Washington State:** The Salish Sea, particularly around the San Juan Islands, is famous for its resident orca population (Southern Resident Killer Whales).  These are endangered orcas, and viewing should be done responsibly with reputable tour operators who prioritize the whales\\' well-being.\\n\\n* **California:** Orcas are seen less frequently in California than in Alaska or Washington, but they do pass through the waters off the coast.  Sightings are less predictable.\\n\\n**To help me narrow down the best place for *you*, tell me:**\\n\\n* **What time of year are you planning to go?**  Orca sightings vary seasonally.\\n* **What kind of experience are you looking for?**  A small boat tour for a closer look? A larger whale-watching cruise?  A land-based viewing opportunity?\\n* **What\\'s your budget?**  Tours can range significantly in price.\\n\\nOnce I have this information, I can give you a more specific recommendation.' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []} id='run-869d89da-2a09-4e7b-bd8a-9d98e84d06aa-0' usage_metadata={'input_tokens': 47, 'output_tokens': 384, 'total_tokens': 431, 'input_token_details': {'cache_read': 0}}\n"
     ]
    }
   ],
   "source": [
    "# Now we can instantiate our model object and gnerate hat completions\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",\n",
    "    temperature=0.2,\n",
    "    max_tokens=512,\n",
    "    timeout=None,\n",
    "    max_retries=2\n",
    ")\n",
    "result = llm.invoke(messages)\n",
    "type(result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f158aec4-15b2-400a-8bc7-6affc2c9b466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt_feedback': {'block_reason': 0, 'safety_ratings': []},\n",
       " 'finish_reason': 'STOP',\n",
       " 'safety_ratings': []}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.response_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71261f55-f2a1-41a2-9e89-ea32a0c17295",
   "metadata": {},
   "source": [
    "### Tools\n",
    "Tools are useful whenever you want a model to interact with external systems.\n",
    "External systems (e.g., APIs) often require a particular input schema or playload, rather than natural language.\n",
    "When we buind an API, fro example, as a tool we given the model awareness of the required input schema.\n",
    "The model will choose to call a tool based upon the natural language input from the user.\n",
    "And, it will reurn an output that adheres to the tools schema.\n",
    "You can simply pass any Python `function` into `ChatModel.bind_tools(function)`\n",
    "\n",
    "Let's showcase a simple example of tool calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b90d7ece-9d24-4cf9-93ec-163c76c974aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The multiple function is our tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"\n",
    "    Multiply a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int \n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "llm_with_tools = llm.bind_tools([multiply])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ebac33-aec0-4f4b-8146-4eeaf4377d41",
   "metadata": {},
   "source": [
    "If we pass an input - e.g., \"What is 3 multiplied by 7 \" -we see a tool call returned.\n",
    "The tool call has specific arguments that match the input schema of our function along with the name of the funtion to call.\n",
    "`{'arguments': '{\"a\": 3, \"b\": 7}', \"name\": 'multiply'}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1b756f0-e2d8-4019-8ee3-709ee4403bee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'name': 'multiply', 'arguments': '{\"a\": 3.0, \"b\": 7.0}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-e910f471-9d16-430e-bb3d-95c6f9ed9228-0', tool_calls=[{'name': 'multiply', 'args': {'a': 3.0, 'b': 7.0}, 'id': 'd7702d65-c0fe-4fed-ae00-e08491a79fb8', 'type': 'tool_call'}], usage_metadata={'input_tokens': 57, 'output_tokens': 3, 'total_tokens': 60, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_call = llm_with_tools.invoke([HumanMessage(content=f\"What is 3 multiplied by 7\", name=\"BiaoGe\")])\n",
    "tool_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebb15c68-3b89-446b-a583-b73e997d0dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'multiply', 'arguments': '{\"a\": 3.0, \"b\": 7.0}'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_call.additional_kwargs['function_call']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05488a19-a806-4255-a949-1f79c9cfd74d",
   "metadata": {},
   "source": [
    "### Using messages as state\n",
    "With these fundations in place, we can now use `messages` in our graph state.\n",
    "Let's define our state, `MessagesState`, as a `TypeDict` with a single key: `messages`.\n",
    "`messages` is simply a list of messages, as we defined above (e.g., `HumanMessage`, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d00b3eb-8b79-4974-baee-77e1d2d85620",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import AnyMessage\n",
    "\n",
    "class MessagesState(TypedDict):\n",
    "    messages: list[AnyMessage]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8f1f66-9db2-4762-b3d2-113e5458f36a",
   "metadata": {},
   "source": [
    "### Reducers\n",
    "Now, we have a minor problem!\n",
    "As we discussed, each node will return a new value for our state key `messages`.\n",
    "But, this new value will override to the prior `messages` value.\n",
    "As our graph runs, we want to append message to our `messages` state key.\n",
    "We can use `reducer functions` address this.\n",
    "Reducers allow us to specify how state updates are performed.\n",
    "If no reducer function is sepcifed, then it is assumed that updates to the key should override it as we saw before.\n",
    "But, to append messages, we can use the pre-build add_messages reducer.\n",
    "The ensures that any messges are appended to the existing list of messages\n",
    "We annotate simply need to annotate our `messages` key with the `add_messages` reducer function as metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9eab0677-fe63-4b33-baa5-27d54c181d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class MessagesState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6f561a-9f1c-4e9a-b0fb-9f08a24a7084",
   "metadata": {},
   "source": [
    "Since having a list of messages in graph state is so common. LangGraph has a pre-build `MessageSate`\n",
    "`MessagesState` is defined:\n",
    "\n",
    "- With a pre-build single `messages` key\n",
    "- This is a list of `AnyMessage` objects\n",
    "- It uses the `add_messages` reducer\n",
    "We'll usually use `MessagesState` because it is less verbose than defining a custom `TypeDict` as shown above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60c63fe8-aa4b-4058-bfe5-41cd8c9e761d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState\n",
    "\n",
    "class MessagesState(MessagesState):\n",
    "    # Add any keys needed byond messages, which is pre-build\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c04b3b7-5472-4119-a788-51696b8a4bc5",
   "metadata": {},
   "source": [
    "To go a bit deeper, we can see how the `add_messages` reducer works in isolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c6ce072-d172-40b1-b364-ea094d4ecebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='Hello! How can I assist you?', additional_kwargs={}, response_metadata={}, name='Model', id='76536344-809a-4c8d-8edb-e2364e5222be'),\n",
       " HumanMessage(content=\"I'm looking for information on marine biology.\", additional_kwargs={}, response_metadata={}, name='BiaoGe', id='fb4cc9f8-93b9-4fc7-8523-6ea5ee2cfbcd'),\n",
       " AIMessage(content='Sure, I can help with that. What specifically are you interested in?', additional_kwargs={}, response_metadata={}, name='Model', id='04746534-8da3-4062-8aa0-8ac93fa2e551')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initial state\n",
    "initial_messages = [\n",
    "    AIMessage(content=\"Hello! How can I assist you?\", name=\"Model\"),\n",
    "    HumanMessage(content=\"I'm looking for information on marine biology.\", name=\"BiaoGe\")\n",
    "]\n",
    "\n",
    "# New message to add \n",
    "new_message = AIMessage(content=\"Sure, I can help with that. What specifically are you interested in?\", name=\"Model\")\n",
    "\n",
    "# Test \n",
    "add_messages(initial_messages, new_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3481c3d6-882f-45f0-8604-5dc50bade01e",
   "metadata": {},
   "source": [
    "### Our graph\n",
    "Now, lets use `MessagesState` with a graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9313159-b497-4081-ba3d-5b48a3dbac6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "# Node\n",
    "def tool_calling_llm(state: MessagesState):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "# Build graph\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"tool_calling_llm\", tool_calling_llm)\n",
    "builder.add_edge(START, \"tool_calling_llm\")\n",
    "builder.add_edge(\"tool_calling_llm\", END)\n",
    "graph = builder.compile()\n",
    "\n",
    "# View \n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fef269-db15-4dd0-89f1-ab21ed745b25",
   "metadata": {},
   "source": [
    "If we pass in `Hello`, the LLM responds without any tool calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3613f3d-b36f-403f-b627-352ae50341f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hello!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello! How can I help you?\n"
     ]
    }
   ],
   "source": [
    "messages = graph.invoke({\"messages\": HumanMessage(content=\"Hello!\")})\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6238374c-322b-46ca-a981-1d60806ed8d8",
   "metadata": {},
   "source": [
    "The LLM chooses to use tool when it determines that the input or task requires the functionality provided by that tool.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66e93cae-7045-480f-b2ef-faa4249b21ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Multiply 3 and 7\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (b31fb29e-75da-4729-9841-d428362c774f)\n",
      " Call ID: b31fb29e-75da-4729-9841-d428362c774f\n",
      "  Args:\n",
      "    a: 3.0\n",
      "    b: 7.0\n"
     ]
    }
   ],
   "source": [
    "messages = graph.invoke({\"messages\": HumanMessage(content=\"Multiply 3 and 7\")})\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca22554-01aa-4b05-84a5-7e2859a2488f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
