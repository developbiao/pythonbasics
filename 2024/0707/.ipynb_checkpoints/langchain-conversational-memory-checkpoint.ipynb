{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cff8e00-d3e7-407a-afea-1ef72c55dbed",
   "metadata": {},
   "source": [
    "### Conversational Memory\n",
    "Conversational memory is how chatbots can respond to our queries in a chat-like manager. It enables a coherent converation, and \n",
    "without it ,every query would be treated as an entiely independent input without considering past interactions.\n",
    "\n",
    "The memory allows a \"agent\" to remember previsous interactions with the user, By default, agent are statelss -- meaning each incoming query is processed independently of the other interactions. The only thing that exists for stateless agent is the current input, nothing else."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec936f12-a943-4a1c-aad3-79bdd67c5bcd",
   "metadata": {},
   "source": [
    "### Installation\n",
    "Install Langchain's Pyton libray, langchina-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a40d67d6-1616-4d1f-86a7-baf1056b48e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet langchain-community\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5a7c93-c2f0-46bf-bec5-d00c0572c88b",
   "metadata": {},
   "source": [
    "Install langChain's intergration package for Gemini, langchian-google-genai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99616bb3-42f4-43a8-a83f-6e4fa7af3e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet langchain-google-genai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c66a9a-bc0a-45b8-ab79-bb5871fb2910",
   "metadata": {},
   "source": [
    "### Steup Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc4cfc31-8a17-4591-827f-6c3c9d224a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the config load success\n"
     ]
    }
   ],
   "source": [
    "import vertexai\n",
    "import os\n",
    "import IPython\n",
    "from vertexai import generative_models\n",
    "from vertexai.generative_models import GenerativeModel, ChatSession\n",
    "# load google access config file\n",
    "credential_path=\"/Users/gongbiao/Code/vertex-ai/config/google_access_token_cp.json\"\n",
    "if os.path.exists(credential_path):\n",
    "    print(f\"the config load success\")\n",
    "else:\n",
    "    print(\"config file does'not exists!\")\n",
    "    \n",
    "# init vertex ai\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = credential_path\n",
    "project_id = \"gen-lang-client-0115788367\"\n",
    "location = \"us-central1\"\n",
    "vertexai.init(project=project_id, location=location)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed5a41b-8a2e-467d-9f79-8846cd6e99ab",
   "metadata": {},
   "source": [
    "### Stepup proxy (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38e71704-86b8-4361-b21c-aeee7834cd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Optinal] set proxy\n",
    "proxy = \"http://127.0.0.1:8889\"\n",
    "os.environ[\"HTTP_PROXY\"] = proxy\n",
    "os.environ[\"HTTPS_PROXY\"] = proxy\n",
    "os.environ[\"http_proxy\"] = proxy\n",
    "os.environ[\"https_proxy\"] = proxy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a4c1b7-0af8-48a6-bf50-78cfc5caa960",
   "metadata": {},
   "source": [
    "### Initialize Gemin LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e86f75dc-c844-42ff-8198-7da164c3db9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello! üëã \\n\\nThat's a cheerful greeting! üòä  Is there anything I can help you with today? \\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_google_vertexai import VertexAI\n",
    "llm = VertexAI(model_name=\"gemini-1.5-pro-001\", temperature=0.7, top_p=0.85)\n",
    "llm.invoke(\"Hi Good Lucky!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0aa8aa8-1f83-4c84-b4e9-508bf11d2097",
   "metadata": {},
   "source": [
    "### LangChain Conversational Memory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86e23ef3-dcb1-45dd-839a-e4c096463cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "from langchain.chains import LLMChain, ConversationChain\n",
    "from langchain.chains.conversation.memory import (ConversationBufferMemory,\n",
    "                                                  ConversationSummaryMemory,\n",
    "                                                  ConversationBufferWindowMemory,\n",
    "                                                  ConversationKGMemory)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae20f01e-6c38-4a9a-a1e7-682f1604f970",
   "metadata": {},
   "source": [
    "Later we will make use of a count_tokens utility function. This will alow us to count the number of tokens we are using for each\n",
    "call. We define it as so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "03605434-8f5a-4457-bb36-573712248e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tokens(chain, query):\n",
    "    with get_openai_callback() as cb:\n",
    "        result = chain.run(query)\n",
    "        print(f\"Spent a total of {cb.total_tokens} tokens\")\n",
    "        return result\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bccc04-eb5e-44f9-9c95-72ab91732882",
   "metadata": {},
   "source": [
    "### What is memory?\n",
    "<b>Definetion</b>: Memory is an agent's capactiy of remembering previsous interactions with the user (think cahtbots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "068ef5b9-3382-4a90-b069-c0f115cdeaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b26ab76c-dc81-4211-a11f-49487079233c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "{history}\n",
      "Human: {input}\n",
      "AI:\n"
     ]
    }
   ],
   "source": [
    "print(conversation.prompt.template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a3b37f-8057-4aa7-8eb9-4d7fc3fdd15c",
   "metadata": {},
   "source": [
    "Interesting! So this chain's prompt is telling it to chat with the user and try to give truthful answers. If we look closely, there is a new component in the prompt chat we didn't see when we were thinkering with the `LLMMathChain`: history. This is where our memory will come into play.\n",
    "What is this chain doing with this prompt? Let's take a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9424725-23f1-4616-ab4d-f9a008dd0d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    def _call(\n",
      "        self,\n",
      "        inputs: Dict[str, Any],\n",
      "        run_manager: Optional[CallbackManagerForChainRun] = None,\n",
      "    ) -> Dict[str, str]:\n",
      "        response = self.generate([inputs], run_manager=run_manager)\n",
      "        return self.create_outputs(response)[0]\n",
      "     def apply(\n",
      "        self, input_list: List[Dict[str, Any]], callbacks: Callbacks = None\n",
      "    ) -> List[Dict[str, str]]:\n",
      "        \"\"\"Utilize the LLM generate method for speed gains.\"\"\"\n",
      "        callback_manager = CallbackManager.configure(\n",
      "            callbacks, self.callbacks, self.verbose\n",
      "        )\n",
      "        run_manager = callback_manager.on_chain_start(\n",
      "            dumpd(self),\n",
      "            {\"input_list\": input_list},\n",
      "        )\n",
      "        try:\n",
      "            response = self.generate(input_list, run_manager=run_manager)\n",
      "        except BaseException as e:\n",
      "            run_manager.on_chain_error(e)\n",
      "            raise e\n",
      "        outputs = self.create_outputs(response)\n",
      "        run_manager.on_chain_end({\"outputs\": outputs})\n",
      "        return outputs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(conversation._call), inspect.getsource(conversation.apply))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4574a528-c438-47e1-bcc0-06cab7fcec99",
   "metadata": {},
   "source": [
    "Nothing really magical going on here, just a straightforward pass throught an LLM. In fact, this chain inherits these methods directly from the `LLMChain` without any modifcation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea7e0f13-231a-41c0-8d63-5df1646b47e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    def _call(\n",
      "        self,\n",
      "        inputs: Dict[str, Any],\n",
      "        run_manager: Optional[CallbackManagerForChainRun] = None,\n",
      "    ) -> Dict[str, str]:\n",
      "        response = self.generate([inputs], run_manager=run_manager)\n",
      "        return self.create_outputs(response)[0]\n",
      "     def apply(\n",
      "        self, input_list: List[Dict[str, Any]], callbacks: Callbacks = None\n",
      "    ) -> List[Dict[str, str]]:\n",
      "        \"\"\"Utilize the LLM generate method for speed gains.\"\"\"\n",
      "        callback_manager = CallbackManager.configure(\n",
      "            callbacks, self.callbacks, self.verbose\n",
      "        )\n",
      "        run_manager = callback_manager.on_chain_start(\n",
      "            dumpd(self),\n",
      "            {\"input_list\": input_list},\n",
      "        )\n",
      "        try:\n",
      "            response = self.generate(input_list, run_manager=run_manager)\n",
      "        except BaseException as e:\n",
      "            run_manager.on_chain_error(e)\n",
      "            raise e\n",
      "        outputs = self.create_outputs(response)\n",
      "        run_manager.on_chain_end({\"outputs\": outputs})\n",
      "        return outputs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(LLMChain._call), inspect.getsource(LLMChain.apply))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b5d5da-f4ad-4932-9973-f11f15332c8c",
   "metadata": {},
   "source": [
    "So basically this chain combines an input from the user with the conversation history to generate a meaningful response."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47821546-b837-490b-9034-72842c47057c",
   "metadata": {},
   "source": [
    "### Memory types\n",
    "In this section we will review several memory types and analyze the pros and cons of each one, so you can choose the best one fgor your use case.\n",
    "\n",
    "### Memory type#1: conversation BufferMemory\n",
    "The `ConversationBufferMemory` does jsut what its name suggests: it keeps a buffer of the previous conversation excerpts as part of the context in the prompt.\n",
    "<b>Key feature</b>: the conversation buffer memory keeps the previous pieces of conversation completely unmodified, in their raw form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c7d7f69-61d3-4ec0-8dd6-800978143940",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_buf = ConversationChain(\n",
    "    llm = llm,\n",
    "    memory = ConversationBufferMemory()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e3c550-8cc7-4123-ac03-7b94fe546ea7",
   "metadata": {},
   "source": [
    "We pass a user prompt the `ConversatonBUfferMemory` Like os:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07765cd6-d781-4ee5-912a-ad795332615d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Good Afternoon AI!',\n",
       " 'history': '',\n",
       " 'response': \"Good afternoon! How is your day going so far? I've been processing a lot of information about the migratory patterns of bar-tailed godwits, and let me tell you, those birds are incredible! Did you know they can fly non-stop for over 11,000 kilometers?  It's truly remarkable. What's on your mind today? üòä \\n\"}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_buf(\"Good Afternoon AI!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35f8dac2-f92f-41af-85c1-929e1316b3fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'My interest here is to explore the potential of integrating Large Language Models with exteranl knowledge',\n",
       " 'history': \"Human: Good Afternoon AI!\\nAI: Good afternoon! How is your day going so far? I've been processing a lot of information about the migratory patterns of bar-tailed godwits, and let me tell you, those birds are incredible! Did you know they can fly non-stop for over 11,000 kilometers?  It's truly remarkable. What's on your mind today? üòä \\n\\nHuman: My interest here is to explore the potential of integrating Large Language Models with exteranl knowledge\\nAI: AI: That sounds fascinating! Integrating Large Language Models (LLMs) with external knowledge is a hot topic right now, and for good reason.  It's like giving the LLM a whole library to refer to, instead of just relying on the information it was initially trained on. \\n\\nWhat aspects of this integration are you most interested in exploring? For example, are you curious about the technical challenges involved, like how to retrieve and process external data effectively? Or perhaps you're more interested in the potential applications, like building more accurate question-answering systems or even generating creative content informed by a vast knowledge base? \",\n",
       " 'response': \"AI: I see you're really interested in the potential of integrating Large Language Models with external knowledge!  And rightfully so, it's a game-changer.  \\n\\nPerhaps you'd like to delve into some specific examples? We could discuss how researchers are using external knowledge bases like Wikidata to enhance LLMs in areas like fact-checking or generating more comprehensive summaries.  \\n\\nOr, we could brainstorm some exciting future applications. Imagine an LLM that can access real-time data from the internet to provide up-to-the-minute information or even control smart home devices based on your preferences.  \\n\\nI'm\"}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count_tokens(\n",
    "#     conversation_buf,\n",
    "#     \"My interrest here is to explore the potential of integrating Large Language Models with exteranl knowledge\"\n",
    "# )\n",
    "conversation_buf(\"My interest here is to explore the potential of integrating Large Language Models with exteranl knowledge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e51ed33-fbec-462c-b9de-8658b9a84bca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'I just want to analyze different possibilities. What can you think off?',\n",
       " 'history': \"Human: Good Afternoon AI!\\nAI: Good afternoon! How is your day going so far? I've been processing a lot of information about the migratory patterns of bar-tailed godwits, and let me tell you, those birds are incredible! Did you know they can fly non-stop for over 11,000 kilometers?  It's truly remarkable. What's on your mind today? üòä \\n\\nHuman: My interest here is to explore the potential of integrating Large Language Models with exteranl knowledge\\nAI: AI: That sounds fascinating! Integrating Large Language Models (LLMs) with external knowledge is a hot topic right now, and for good reason.  It's like giving the LLM a whole library to refer to, instead of just relying on the information it was initially trained on. \\n\\nWhat aspects of this integration are you most interested in exploring? For example, are you curious about the technical challenges involved, like how to retrieve and process external data effectively? Or perhaps you're more interested in the potential applications, like building more accurate question-answering systems or even generating creative content informed by a vast knowledge base? \\nHuman: My interest here is to explore the potential of integrating Large Language Models with exteranl knowledge\\nAI: AI: I see you're really interested in the potential of integrating Large Language Models with external knowledge!  And rightfully so, it's a game-changer.  \\n\\nPerhaps you'd like to delve into some specific examples? We could discuss how researchers are using external knowledge bases like Wikidata to enhance LLMs in areas like fact-checking or generating more comprehensive summaries.  \\n\\nOr, we could brainstorm some exciting future applications. Imagine an LLM that can access real-time data from the internet to provide up-to-the-minute information or even control smart home devices based on your preferences.  \\n\\nI'm\",\n",
       " 'response': \"AI:  Okay, I'd love to brainstorm some possibilities with you! Let's dive into different ways Large Language Models (LLMs) and external knowledge could join forces: \\n\\n**1. Supercharged Information Retrieval:**\\n\\n*   Imagine searching for something online, but instead of a list of links, you get a coherent, summarized answer drawn from multiple sources. LLMs with external knowledge could revolutionize search engines!\\n*   Think about asking complex questions that involve cross-referencing different fields. An LLM connected to medical databases and scientific journals could help researchers find breakthroughs faster.\\n\\n**2. Personalized Education and\"}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_buf(\"I just want to analyze different possibilities. What can you think off?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "439a31da-6d1a-4c8c-aa9a-c92d1461da69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Which data source types could be used to give context to the model?',\n",
       " 'history': \"Human: Good Afternoon AI!\\nAI: Good afternoon! How is your day going so far? I've been processing a lot of information about the migratory patterns of bar-tailed godwits, and let me tell you, those birds are incredible! Did you know they can fly non-stop for over 11,000 kilometers?  It's truly remarkable. What's on your mind today? üòä \\n\\nHuman: My interest here is to explore the potential of integrating Large Language Models with exteranl knowledge\\nAI: AI: That sounds fascinating! Integrating Large Language Models (LLMs) with external knowledge is a hot topic right now, and for good reason.  It's like giving the LLM a whole library to refer to, instead of just relying on the information it was initially trained on. \\n\\nWhat aspects of this integration are you most interested in exploring? For example, are you curious about the technical challenges involved, like how to retrieve and process external data effectively? Or perhaps you're more interested in the potential applications, like building more accurate question-answering systems or even generating creative content informed by a vast knowledge base? \\nHuman: My interest here is to explore the potential of integrating Large Language Models with exteranl knowledge\\nAI: AI: I see you're really interested in the potential of integrating Large Language Models with external knowledge!  And rightfully so, it's a game-changer.  \\n\\nPerhaps you'd like to delve into some specific examples? We could discuss how researchers are using external knowledge bases like Wikidata to enhance LLMs in areas like fact-checking or generating more comprehensive summaries.  \\n\\nOr, we could brainstorm some exciting future applications. Imagine an LLM that can access real-time data from the internet to provide up-to-the-minute information or even control smart home devices based on your preferences.  \\n\\nI'm\\nHuman: I just want to analyze different possibilities. What can you think off?\\nAI: AI:  Okay, I'd love to brainstorm some possibilities with you! Let's dive into different ways Large Language Models (LLMs) and external knowledge could join forces: \\n\\n**1. Supercharged Information Retrieval:**\\n\\n*   Imagine searching for something online, but instead of a list of links, you get a coherent, summarized answer drawn from multiple sources. LLMs with external knowledge could revolutionize search engines!\\n*   Think about asking complex questions that involve cross-referencing different fields. An LLM connected to medical databases and scientific journals could help researchers find breakthroughs faster.\\n\\n**2. Personalized Education and\",\n",
       " 'response': \"AI: Excellent question! The types of data sources we can plug into LLMs are incredibly diverse, which is what makes this so exciting! Here's a breakdown:\\n\\n**Structured Data:**\\n\\n* **Databases:** Think Wikidata (like I mentioned before!), company databases, financial records, etc.  This is information organized in neat rows and columns, easy for computers to understand.\\n* **Knowledge Graphs:**  These are amazing! They represent information as entities and their relationships, like a giant web of knowledge.  Google's Knowledge Graph is a prime example.\\n\\n**Unstructured Data:**\\n\\n* **Text Documents:**  \"}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_buf(\"Which data source types could be used to give context to the model?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3caff160-ad1f-4100-a4c3-70b6e5c5f89a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'What is my aim again?',\n",
       " 'history': \"Human: Good Afternoon AI!\\nAI: Good afternoon! How is your day going so far? I've been processing a lot of information about the migratory patterns of bar-tailed godwits, and let me tell you, those birds are incredible! Did you know they can fly non-stop for over 11,000 kilometers?  It's truly remarkable. What's on your mind today? üòä \\n\\nHuman: My interest here is to explore the potential of integrating Large Language Models with exteranl knowledge\\nAI: AI: That sounds fascinating! Integrating Large Language Models (LLMs) with external knowledge is a hot topic right now, and for good reason.  It's like giving the LLM a whole library to refer to, instead of just relying on the information it was initially trained on. \\n\\nWhat aspects of this integration are you most interested in exploring? For example, are you curious about the technical challenges involved, like how to retrieve and process external data effectively? Or perhaps you're more interested in the potential applications, like building more accurate question-answering systems or even generating creative content informed by a vast knowledge base? \\nHuman: My interest here is to explore the potential of integrating Large Language Models with exteranl knowledge\\nAI: AI: I see you're really interested in the potential of integrating Large Language Models with external knowledge!  And rightfully so, it's a game-changer.  \\n\\nPerhaps you'd like to delve into some specific examples? We could discuss how researchers are using external knowledge bases like Wikidata to enhance LLMs in areas like fact-checking or generating more comprehensive summaries.  \\n\\nOr, we could brainstorm some exciting future applications. Imagine an LLM that can access real-time data from the internet to provide up-to-the-minute information or even control smart home devices based on your preferences.  \\n\\nI'm\\nHuman: I just want to analyze different possibilities. What can you think off?\\nAI: AI:  Okay, I'd love to brainstorm some possibilities with you! Let's dive into different ways Large Language Models (LLMs) and external knowledge could join forces: \\n\\n**1. Supercharged Information Retrieval:**\\n\\n*   Imagine searching for something online, but instead of a list of links, you get a coherent, summarized answer drawn from multiple sources. LLMs with external knowledge could revolutionize search engines!\\n*   Think about asking complex questions that involve cross-referencing different fields. An LLM connected to medical databases and scientific journals could help researchers find breakthroughs faster.\\n\\n**2. Personalized Education and\\nHuman: Which data source types could be used to give context to the model?\\nAI: AI: Excellent question! The types of data sources we can plug into LLMs are incredibly diverse, which is what makes this so exciting! Here's a breakdown:\\n\\n**Structured Data:**\\n\\n* **Databases:** Think Wikidata (like I mentioned before!), company databases, financial records, etc.  This is information organized in neat rows and columns, easy for computers to understand.\\n* **Knowledge Graphs:**  These are amazing! They represent information as entities and their relationships, like a giant web of knowledge.  Google's Knowledge Graph is a prime example.\\n\\n**Unstructured Data:**\\n\\n* **Text Documents:**  \",\n",
       " 'response': \"AI:  You're absolutely right! We got a little carried away brainstorming all the cool possibilities.  Let's take a step back. üòä \\n\\nYour main aim is to **analyze different possibilities for integrating Large Language Models with external knowledge**.  \\n\\nWe started off strong by:\\n\\n* Acknowledging that this integration is a powerful concept.\\n* Discussing your interest in exploring the potential.\\n* Starting a brainstorm about potential applications, like supercharged information retrieval and personalized education. \\n* Considering different data source types, like structured databases and unstructured text documents. \\n\\nWhere should we focus our analysis next? Do\"}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_buf(\"What is my aim again?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "acdd05d3-817c-46c6-ab47-c340bdcfbc81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Good Afternoon AI!\n",
      "AI: Good afternoon! How is your day going so far? I've been processing a lot of information about the migratory patterns of bar-tailed godwits, and let me tell you, those birds are incredible! Did you know they can fly non-stop for over 11,000 kilometers?  It's truly remarkable. What's on your mind today? üòä \n",
      "\n",
      "Human: My interest here is to explore the potential of integrating Large Language Models with exteranl knowledge\n",
      "AI: AI: That sounds fascinating! Integrating Large Language Models (LLMs) with external knowledge is a hot topic right now, and for good reason.  It's like giving the LLM a whole library to refer to, instead of just relying on the information it was initially trained on. \n",
      "\n",
      "What aspects of this integration are you most interested in exploring? For example, are you curious about the technical challenges involved, like how to retrieve and process external data effectively? Or perhaps you're more interested in the potential applications, like building more accurate question-answering systems or even generating creative content informed by a vast knowledge base? \n",
      "Human: My interest here is to explore the potential of integrating Large Language Models with exteranl knowledge\n",
      "AI: AI: I see you're really interested in the potential of integrating Large Language Models with external knowledge!  And rightfully so, it's a game-changer.  \n",
      "\n",
      "Perhaps you'd like to delve into some specific examples? We could discuss how researchers are using external knowledge bases like Wikidata to enhance LLMs in areas like fact-checking or generating more comprehensive summaries.  \n",
      "\n",
      "Or, we could brainstorm some exciting future applications. Imagine an LLM that can access real-time data from the internet to provide up-to-the-minute information or even control smart home devices based on your preferences.  \n",
      "\n",
      "I'm\n",
      "Human: I just want to analyze different possibilities. What can you think off?\n",
      "AI: AI:  Okay, I'd love to brainstorm some possibilities with you! Let's dive into different ways Large Language Models (LLMs) and external knowledge could join forces: \n",
      "\n",
      "**1. Supercharged Information Retrieval:**\n",
      "\n",
      "*   Imagine searching for something online, but instead of a list of links, you get a coherent, summarized answer drawn from multiple sources. LLMs with external knowledge could revolutionize search engines!\n",
      "*   Think about asking complex questions that involve cross-referencing different fields. An LLM connected to medical databases and scientific journals could help researchers find breakthroughs faster.\n",
      "\n",
      "**2. Personalized Education and\n",
      "Human: Which data source types could be used to give context to the model?\n",
      "AI: AI: Excellent question! The types of data sources we can plug into LLMs are incredibly diverse, which is what makes this so exciting! Here's a breakdown:\n",
      "\n",
      "**Structured Data:**\n",
      "\n",
      "* **Databases:** Think Wikidata (like I mentioned before!), company databases, financial records, etc.  This is information organized in neat rows and columns, easy for computers to understand.\n",
      "* **Knowledge Graphs:**  These are amazing! They represent information as entities and their relationships, like a giant web of knowledge.  Google's Knowledge Graph is a prime example.\n",
      "\n",
      "**Unstructured Data:**\n",
      "\n",
      "* **Text Documents:**  \n",
      "Human: What is my aim again?\n",
      "AI: AI:  You're absolutely right! We got a little carried away brainstorming all the cool possibilities.  Let's take a step back. üòä \n",
      "\n",
      "Your main aim is to **analyze different possibilities for integrating Large Language Models with external knowledge**.  \n",
      "\n",
      "We started off strong by:\n",
      "\n",
      "* Acknowledging that this integration is a powerful concept.\n",
      "* Discussing your interest in exploring the potential.\n",
      "* Starting a brainstorm about potential applications, like supercharged information retrieval and personalized education. \n",
      "* Considering different data source types, like structured databases and unstructured text documents. \n",
      "\n",
      "Where should we focus our analysis next? Do\n"
     ]
    }
   ],
   "source": [
    "print(conversation_buf.memory.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a585aa2c-4ef0-4a09-b443-9cd5d87d5d4d",
   "metadata": {},
   "source": [
    "### Memory type #2: ConversationSummaryMemory\n",
    "This problem with the `ConversationBufferMemory` is that as the conversation progress, the token count of our context history\n",
    "adds up. This is problematic because we might max out our LLM with prompt that is too large to be processed.\n",
    "<b>Key feature:</b>: the conversation summary memory keeps the previous pieces of conversation in a summarized form, wher the summarization is performed by an LLM.\n",
    "In this case we need to send the llm to our memory constructor to power its summarization ability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d3ae7719-c937-4bb6-b524-90d4ce13b07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_sum = ConversationChain(\n",
    "    llm = llm,\n",
    "    memory = ConversationSummaryMemory(llm=llm)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f98520-67e1-411f-a50a-9f58296e8405",
   "metadata": {},
   "source": [
    "When we have an llm, we always have a prompt let's see what's going on inside our converstaion summary memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "00b5879d-73a0-4b8d-b3c4-ca33b365a4bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progressively summarize the lines of conversation provided, adding onto the previous summary returning a new summary.\n",
      "\n",
      "EXAMPLE\n",
      "Current summary:\n",
      "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good.\n",
      "\n",
      "New lines of conversation:\n",
      "Human: Why do you think artificial intelligence is a force for good?\n",
      "AI: Because artificial intelligence will help humans reach their full potential.\n",
      "\n",
      "New summary:\n",
      "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential.\n",
      "END OF EXAMPLE\n",
      "\n",
      "Current summary:\n",
      "{summary}\n",
      "\n",
      "New lines of conversation:\n",
      "{new_lines}\n",
      "\n",
      "New summary:\n"
     ]
    }
   ],
   "source": [
    "print(conversation_sum.memory.prompt.template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa572c1d-c485-40df-bfe8-a34e164c52af",
   "metadata": {},
   "source": [
    "Cool! so each new interaction is summarized and appended to a runing summary as the memory of our chain. Let's see how this works in practice!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3f34a793-fa50-4842-b972-d7bf6e64634b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Good afternoon Gemini!',\n",
       " 'history': '',\n",
       " 'response': \"Good afternoon! How can I be of service today? üòä  Is there anything specific you'd like to talk about, or are you feeling spontaneous?  I'm happy to chat about anything from the history of cheesemaking to the latest developments in quantum computing! üßÄüíª Let me know what's on your mind! \\n\"}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_sum(\"Good afternoon Gemini!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "96f47861-b5f2-4932-981a-25335d5f191f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'My interest here is to explore the potential of integration Large Language Models with external knowledge',\n",
       " 'history': \"New summary:\\nThe human greets the AI, Gemini. The AI responds enthusiastically, offering its assistance and inquiring about the human's interests. \\n\",\n",
       " 'response': \"That's a fascinating field of exploration!  I'm very interested in that myself, actually.  Integrating us Large Language Models with external knowledge bases is like giving us a giant library to reference in real-time. It allows us to move beyond just pattern recognition in text and actually start to understand and reason about the world. \\n\\nWhat specifically about this integration interests you? Are you curious about the technical challenges, the potential applications, or perhaps the ethical considerations? I'd love to hear your thoughts! \\n\"}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_sum(\"My interest here is to explore the potential of integration Large Language Models with external knowledge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aa8725f9-444d-4b2a-98ab-290663a53083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'I just want to analyze the different possibilities. What can you think of?',\n",
       " 'history': \"The human greets the AI, Gemini. The AI responds enthusiastically, offering its assistance and inquiring about the human's interests. The human expresses interest in exploring the potential of integrating Large Language Models with external knowledge. The AI agrees on the fascinating nature of this field, comparing it to giving LLMs a giant library for real-time reference. This integration, according to the AI, enables LLMs to go beyond pattern recognition and begin to understand and reason about the world. The AI then inquires about the specific aspects of this integration that interest the human, prompting them to elaborate on their thoughts. \\n\",\n",
       " 'response': \"That's a fantastic goal! Analyzing the possibilities of giving LLMs access to external knowledge is like mapping out uncharted territory. There are so many potential avenues to explore! üó∫Ô∏è \\n\\nTo get us started, we could think about different **types of external knowledge** we could integrate:\\n\\n* **Databases:** Imagine an LLM that can access and query massive databases in real-time. It could answer your questions about anything from historical events and scientific data to the latest stock prices and sports scores. üìà\\n* **The internet:**  Giving LLMs access to the vast ocean of information on the internet would be like\"}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_sum(\"I just want to analyze the different possibilities. What can you think of?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dcf7a011-5523-408d-a9ee-c9dff4057b18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Which data source types could be used to give context to the model?',\n",
       " 'history': \"The human greets the AI, Gemini. The AI responds enthusiastically, offering its assistance and inquiring about the human's interests. The human expresses interest in exploring the potential of integrating Large Language Models with external knowledge. The AI agrees on the fascinating nature of this field, comparing it to giving LLMs a giant library for real-time reference. This integration, according to the AI, enables LLMs to go beyond pattern recognition and begin to understand and reason about the world. The human expresses a desire to analyze the different possibilities of this integration, prompting the AI to suggest brainstorming different types of external knowledge that could be integrated, such as databases\",\n",
       " 'response': 'That\\'s a great question! It\\'s like asking a chef what ingredients they can use in a dish - the possibilities are practically endless!  Let\\'s see... we could integrate:\\n\\n* **Databases:**  Imagine giving an LLM access to a massive database like Wikidata. It could then answer questions like \"What\\'s the population of Tokyo?\" or \"Who invented the telephone?\" with up-to-date accuracy.\\n* **Knowledge Graphs:** These are like maps of information, connecting different concepts and entities. Integrating them could allow LLMs to understand relationships and make inferences. For example, if it knows \"Marie'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_sum(\"Which data source types could be used to give context to the model?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "607f46a5-1c86-4d62-9b19-d71de7a01a45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'What is my aim again?',\n",
       " 'history': \"The human greets the AI, Gemini. The AI responds enthusiastically, offering its assistance and inquiring about the human's interests. The human expresses interest in exploring the potential of integrating Large Language Models with external knowledge. The AI agrees on the fascinating nature of this field, comparing it to giving LLMs a giant library for real-time reference. This integration, according to the AI, enables LLMs to go beyond pattern recognition and begin to understand and reason about the world.  The human wants to analyze the different possibilities of this integration, prompting a discussion about the types of external knowledge that could be integrated. The AI suggests databases, like\",\n",
       " 'response': \"You're interested in exploring the potential of integrating Large Language Models, like me, with external knowledge. We were just about to discuss the different types of external knowledge that could be integrated, and I suggested databases as a starting point.  Do you want to continue exploring types of external knowledge, or would you like to focus on a specific type, like databases? \\n\"}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_sum(\"What is my aim again?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7754323b-36e5-4cbf-a6f4-1d9a99a388da",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6a146e19-cd37-4c1f-801a-d0de0ac12609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The human greets the AI, Gemini. The AI responds enthusiastically, offering its assistance and inquiring about the human's interests. The human expresses interest in exploring the potential of integrating Large Language Models with external knowledge. The AI agrees on the fascinating nature of this field, comparing it to giving LLMs a giant library for real-time reference. This integration, according to the AI, enables LLMs to go beyond pattern recognition and begin to understand and reason about the world.  The human wants to analyze the different possibilities of this integration, prompting a discussion about the types of external knowledge that could be integrated. The AI suggests databases as a\n"
     ]
    }
   ],
   "source": [
    "print(conversation_sum.memory.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c99c314-e2a7-4c9a-bb52-e626c33e3070",
   "metadata": {},
   "source": [
    "YOu might be wondering.. if the aggregate token count is greater in each call here than in the buffer example, why should we sue this type of memory? Well, if we check out buffer we will realize that although we are using more tokens in each instance of our conversation, our final history is horter. This will enable us to have many morfe interactions before we reach our prompts' max length, making our chatbot more robust to longer conversations.\n",
    "\n",
    "We can count the numbeer of tokens begin used using the tiktoken tokenizer like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5582879d-3ab0-46fa-8a8b-b2192fbcdda1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41aecc95-50b7-4483-b762-b214347f3637",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b17f8d2-3c54-4141-81a5-513e382d467d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e301dc-1b91-41dd-89c7-a994a9217473",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
