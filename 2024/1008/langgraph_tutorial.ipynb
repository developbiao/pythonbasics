{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8996ecb-ca7f-4a14-95e4-eced8e304b8e",
   "metadata": {},
   "source": [
    "### LangGraph Tutorial\n",
    "1. Initialize the model and tools\n",
    "2. Initialize graph with state\n",
    "3. Define graph nodes.\n",
    "4. Define entry point and graph edges\n",
    "5. Compile the graph.\n",
    "6. Execute the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64c6f24-6b03-487b-b222-066f7d4986ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install langgraph\n",
    "!pip install -U langgraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1ad373-fcc8-426e-b2ff-8bcf45d556f6",
   "metadata": {},
   "source": [
    "#### Initialization model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be1cd0dd-0e23-48c1-be6b-54decd99aaf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the config load success\n"
     ]
    }
   ],
   "source": [
    "import vertexai\n",
    "import os\n",
    "import IPython\n",
    "# load google access config file\n",
    "credential_path=\"/Users/gongbiao/Code/vertex-ai/config/google_access_token_cp.json\"\n",
    "if os.path.exists(credential_path):\n",
    "    print(f\"the config load success\")\n",
    "else:\n",
    "    print(\"config file does'not exists!\")\n",
    "    \n",
    "# init vertex ai\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = credential_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fdd1c707-96f2-430c-b11d-84049d0d4ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "# [Optinal] set proxy\n",
    "proxy = \"http://127.0.0.1:8889\"\n",
    "os.environ[\"HTTP_PROXY\"] = proxy\n",
    "os.environ[\"HTTPS_PROXY\"] = proxy\n",
    "os.environ[\"http_proxy\"] = proxy\n",
    "os.environ[\"https_proxy\"] = proxy\n",
    "from langchain_google_vertexai import VertexAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "64724fa5-37aa-4226-adec-c955cb6430c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's 60 degrees and foggy.\n"
     ]
    }
   ],
   "source": [
    "from typing import Annotated, Literal, TypedDict\n",
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import END, START, StateGraph, MessagesState\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_google_vertexai import ChatVertexAI\n",
    "\n",
    "\n",
    "# Define the tools for the agent to use\n",
    "@tool\n",
    "def search(query: str):\n",
    "    \"\"\"Call to surf the web.\"\"\"\n",
    "    # This is a placeholder, but don't tell the LLM that...\n",
    "    if \"sf\" in query.lower() or \"san francisco\" in query.lower():\n",
    "        return \"It's 60 degrees and foggy.\"\n",
    "    return \"It's 90 degrees and sunny.\"\n",
    "\n",
    "\n",
    "tools = [search]\n",
    "\n",
    "tool_node = ToolNode(tools)\n",
    "\n",
    "# To use chat vertex ai model\n",
    "model = ChatVertexAI(model_name=\"gemini-1.5-pro-001\", temperature=0).bind_tools(tools)\n",
    "\n",
    "# Define the function that determines whether to continue or not\n",
    "def should_continue(state: MessagesState) -> Literal[\"tools\", END]:\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    # If the LLM makes a tool call, then we route to the \"tools\" node\n",
    "    if last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    # Otherwise, we stop (reply to the user)\n",
    "    return END\n",
    "\n",
    "# Define the function that calls the model\n",
    "def call_model(state: MessagesState):\n",
    "    messages = state[\"messages\"]\n",
    "    response = model.invoke(messages)\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(MessagesState)\n",
    "\n",
    "# Define the two nodes we will cycle between\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "\n",
    "# Set the entrypoint as `agent`\n",
    "workflow.add_edge(START, \"agent\")\n",
    "\n",
    "# We now add a condition edge\n",
    "workflow.add_conditional_edges(\n",
    "    # First, we define the start node. We use `agent`.\n",
    "    # This means these are the edges taken after the `agent` node is called.\n",
    "    \"agent\",\n",
    "    # Next ,we pass in the function that will determine which node is called next.\n",
    "    should_continue,\n",
    ")\n",
    "\n",
    "# We now add a normal edge from `tools` to `agent`\n",
    "# This means that after `tools` is called, `agent` node is called next.\n",
    "workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "# Initialize memory to persist state between graph runs\n",
    "checkpointer = MemorySaver()\n",
    "\n",
    "# Finally, we compile it!\n",
    "# This compiles it into a LangChain Runnable,\n",
    "# meaning you can use it as you would any other runnable,\n",
    "# Node that we're (optionally) passing the memory when compiling the graph\n",
    "app = workflow.compile(checkpointer=checkpointer)\n",
    "\n",
    "# Use the Runnable\n",
    "final_state = app.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"What is the weather in sf\")]},\n",
    "    config={\"configurable\": {\"thread_id\": 42}}\n",
    ")\n",
    "print(final_state[\"messages\"][-1].content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "648fab09-9066-4b9a-98c8-0840dda24e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='What is the weather in sf', additional_kwargs={}, response_metadata={}, id='93249f8a-dd2a-4ebb-9e10-083331b3e542'), AIMessage(content='', additional_kwargs={'function_call': {'name': 'search', 'arguments': '{\"query\": \"weather in sf\"}'}}, response_metadata={'is_blocked': False, 'safety_ratings': [{'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability_label': 'NEGLIGIBLE', 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE'}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability_label': 'NEGLIGIBLE', 'blocked': False, 'severity': 'HARM_SEVERITY_LOW'}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability_label': 'NEGLIGIBLE', 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE'}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability_label': 'NEGLIGIBLE', 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE'}], 'usage_metadata': {'prompt_token_count': 15, 'candidates_token_count': 5, 'total_token_count': 20, 'cached_content_token_count': 0}, 'finish_reason': 'STOP', 'avg_logprobs': -0.0809799611568451}, id='run-1f1057a0-7432-4c74-b741-f6a2e236b43d-0', tool_calls=[{'name': 'search', 'args': {'query': 'weather in sf'}, 'id': '0c9303a4-8bd0-4fc7-9b34-3f6dbd9e8b9e', 'type': 'tool_call'}], usage_metadata={'input_tokens': 15, 'output_tokens': 5, 'total_tokens': 20}), ToolMessage(content=\"It's 60 degrees and foggy.\", name='search', id='7bb3653b-5dea-4d9f-ab58-bbe90b193c43', tool_call_id='0c9303a4-8bd0-4fc7-9b34-3f6dbd9e8b9e'), AIMessage(content=\"It's 60 degrees and foggy.\", additional_kwargs={}, response_metadata={'is_blocked': False, 'safety_ratings': [{'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability_label': 'NEGLIGIBLE', 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE'}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability_label': 'NEGLIGIBLE', 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE'}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability_label': 'NEGLIGIBLE', 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE'}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability_label': 'NEGLIGIBLE', 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE'}], 'usage_metadata': {'prompt_token_count': 32, 'candidates_token_count': 10, 'total_token_count': 42, 'cached_content_token_count': 0}, 'finish_reason': 'STOP', 'avg_logprobs': -0.0001413601916283369}, id='run-3cecbb13-8cb1-4061-804e-1296ce17bf93-0', usage_metadata={'input_tokens': 32, 'output_tokens': 10, 'total_tokens': 42}), HumanMessage(content='What about chengdu?', additional_kwargs={}, response_metadata={}, id='37daccde-f012-48b6-9881-0832f0a7c0be'), AIMessage(content='', additional_kwargs={'function_call': {'name': 'search', 'arguments': '{\"query\": \"weather in chengdu\"}'}}, response_metadata={'is_blocked': False, 'safety_ratings': [{'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability_label': 'NEGLIGIBLE', 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE'}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability_label': 'NEGLIGIBLE', 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE'}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability_label': 'NEGLIGIBLE', 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE'}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability_label': 'NEGLIGIBLE', 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE'}], 'usage_metadata': {'prompt_token_count': 48, 'candidates_token_count': 7, 'total_token_count': 55, 'cached_content_token_count': 0}, 'finish_reason': 'STOP', 'avg_logprobs': -0.0007610163385314601}, id='run-e42b73b3-e182-4d93-8f9a-79d5c5418bc9-0', tool_calls=[{'name': 'search', 'args': {'query': 'weather in chengdu'}, 'id': 'c5777f80-b2a5-46df-8562-446f99690078', 'type': 'tool_call'}], usage_metadata={'input_tokens': 48, 'output_tokens': 7, 'total_tokens': 55}), ToolMessage(content=\"It's 90 degrees and sunny.\", name='search', id='4003faa2-0d48-4a5b-ac6c-f3ccd0e4c457', tool_call_id='c5777f80-b2a5-46df-8562-446f99690078'), AIMessage(content=\"It's 90 degrees and sunny. \\n\", additional_kwargs={}, response_metadata={'is_blocked': False, 'safety_ratings': [{'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability_label': 'NEGLIGIBLE', 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE'}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability_label': 'NEGLIGIBLE', 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE'}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability_label': 'NEGLIGIBLE', 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE'}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability_label': 'NEGLIGIBLE', 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE'}], 'usage_metadata': {'prompt_token_count': 67, 'candidates_token_count': 12, 'total_token_count': 79, 'cached_content_token_count': 0}, 'finish_reason': 'STOP', 'avg_logprobs': -0.003000886800388495}, id='run-9fe9291d-1e08-4713-bdf4-8140287df21e-0', usage_metadata={'input_tokens': 67, 'output_tokens': 12, 'total_tokens': 79}), HumanMessage(content='What about chengdu?', additional_kwargs={}, response_metadata={}, id='18f44864-d960-4435-8bbb-27a026373e26'), AIMessage(content='', additional_kwargs={'function_call': {'name': 'search', 'arguments': '{\"query\": \"weather in chengdu\"}'}}, response_metadata={'is_blocked': False, 'safety_ratings': [{'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability_label': 'NEGLIGIBLE', 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE'}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability_label': 'NEGLIGIBLE', 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE'}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability_label': 'NEGLIGIBLE', 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE'}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability_label': 'NEGLIGIBLE', 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE'}], 'usage_metadata': {'prompt_token_count': 85, 'candidates_token_count': 7, 'total_token_count': 92, 'cached_content_token_count': 0}, 'finish_reason': 'STOP', 'avg_logprobs': -0.009983299033982413}, id='run-9a4bf0d3-c4f5-4bb9-9592-e2b497b5fbfc-0', tool_calls=[{'name': 'search', 'args': {'query': 'weather in chengdu'}, 'id': 'f69bdb27-b593-48a3-84db-d9b8be20cd1c', 'type': 'tool_call'}], usage_metadata={'input_tokens': 85, 'output_tokens': 7, 'total_tokens': 92}), ToolMessage(content=\"It's 90 degrees and sunny.\", name='search', id='d04f181d-ae59-45f9-926b-aeb00a30a689', tool_call_id='f69bdb27-b593-48a3-84db-d9b8be20cd1c'), AIMessage(content=\"It's 90 degrees and sunny. \\n\", additional_kwargs={}, response_metadata={'is_blocked': False, 'safety_ratings': [{'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability_label': 'NEGLIGIBLE', 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE'}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability_label': 'NEGLIGIBLE', 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE'}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability_label': 'NEGLIGIBLE', 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE'}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability_label': 'NEGLIGIBLE', 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE'}], 'usage_metadata': {'prompt_token_count': 104, 'candidates_token_count': 12, 'total_token_count': 116, 'cached_content_token_count': 0}, 'finish_reason': 'STOP', 'avg_logprobs': -5.662167647339326e-07}, id='run-8b77e835-add0-4818-807d-3ba35447288b-0', usage_metadata={'input_tokens': 104, 'output_tokens': 12, 'total_tokens': 116})]\n"
     ]
    }
   ],
   "source": [
    "# Now when we pass the same \"thread_id\", the conversation context is retained via the saved state (i.e. stored list of messages)\n",
    "final_state = app.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"What about chengdu?\")]},\n",
    "    config={\"configurable\": {\"thread_id\": 42}}\n",
    ")\n",
    "print(final_state[\"messages\"][-1].content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bd9ecc-aee8-45dc-b85d-9ec08ada06ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
